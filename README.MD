# ğŸ¤– DocChatter - Chat with Your Documents

DocChatter is an AI-powered document chat application that allows you to upload documents and have intelligent conversations about their content using Google's Gemini AI and advanced RAG (Retrieval-Augmented Generation) technology.

## âœ¨ Features

- ğŸ“„ **Document Upload**: Support for text documents
- ğŸ¤– **AI-Powered Chat**: Intelligent conversations using Google Gemini AI
- ğŸ” **Smart Search**: Vector-based document search using ChromaDB
- ğŸ’¬ **Chat History**: Persistent conversation history
- ğŸ³ **Dockerized**: Easy deployment with Docker
- â˜ï¸ **Cloud Ready**: Optimized for Google Cloud Run deployment

## ğŸ—ï¸ Architecture

- **Frontend**: Streamlit web interface
- **AI Model**: Google Gemini AI via LangChain
- **Vector Database**: ChromaDB for document embeddings
- **Text Processing**: HuggingFace Sentence Transformers
- **Document Processing**: LangChain document loaders and text splitters

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker (optional)
- Google AI API Key (Gemini)

### 1. Clone the Repository

```bash
git clone https://github.com/Karagwa/DocChatter
cd Build_A_Bot
```

### 2. Environment Setup

Create a `.env` file in the root directory:

```env
GOOGLE_API_KEY=your_gemini_api_key_here
PORT =
```

### 3. Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run app/main.py
```

Access the app at: http://localhost:8501

### 4. Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or build and run manually
docker build -t docchatter .
docker run -p 8081:8501 -e PORT=8501 --env-file .env docchatter
```

Access the app at: http://localhost:8081

### Deployed URL
https://docchatter-77068367626.europe-west1.run.app

## ğŸ“ Project Structure

```
Build_A_Bot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Streamlit main application
â”‚   â”œâ”€â”€ rag_pipeline.py      # RAG pipeline implementation
â”‚   â”œâ”€â”€ chroma_langchain_db/ # Vector database storage
â”‚   â””â”€â”€ temp_uploads/        # Temporary file uploads
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile              # Container configuration
â”œâ”€â”€ docker-compose.yaml     # Docker Compose configuration
â”œâ”€â”€ .env                    # Environment variables
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GOOGLE_API_KEY` | Google AI API key for Gemini | Yes |
| `PORT` | Application port (default: 8501) | No |



## ğŸ“‹ Dependencies

### Core Dependencies

```
streamlit              # Web application framework
langchain             # LLM application framework
langchain-google-genai # Google AI integration
chromadb              # Vector database
sentence-transformers # Text embeddings
python-dotenv         # Environment management
```

### Full Dependencies

See `requirements.txt` 

## ğŸ¯ Usage

1. **Start the Application**: Run locally or via Docker
2. **Upload Document**: Use the sidebar to upload a text document
3. **Ask Questions**: Type questions about your document
4. **View Responses**: Get AI-powered answers with context


### Supported File Types

- `.txt` - Plain text files
- More formats can be added by extending the document loaders

## ğŸ› ï¸ Development

### Local Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Run in development mode
streamlit run app/main.py --server.runOnSave=true
```

### Code Structure

- `app/main.py`: Streamlit UI and application logic
- `app/rag_pipeline.py`: Document processing and RAG implementation
- Vector storage in `chroma_langchain_db/`
- Temporary uploads in `temp_uploads/`

## ğŸ” Troubleshooting

### Common Issues

1. **Module Import Errors**: Ensure all dependencies are installed
2. **API Key Issues**: Verify `GOOGLE_API_KEY` is set correctly
3. **Port Conflicts**: Change port mapping in docker-compose.yaml
4. **Memory Issues**: Increase Docker memory limits for large documents

### Docker Issues

```bash
# Rebuild container
docker-compose down
docker-compose up --build

# View logs
docker-compose logs -f

# Check container status
docker-compose ps
```

## ğŸ“Š Performance

- **Memory**: ~1-2GB recommended for typical usage
- **CPU**: Single core sufficient for small to medium documents
- **Storage**: Vector database grows with document size
- **Response Time**: 2-5 seconds depending on query complexity

## ğŸ”’ Security

- API keys stored in environment variables
- No persistent user data storage
- Stateless application design
- Container runs as non-root user (production)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/) for the web framework
- [LangChain](https://langchain.com/) for LLM orchestration
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [Google AI](https://ai.google.dev/) for Gemini API
- [HuggingFace](https://huggingface.co/) for embeddings

## ğŸ“ Support

For issues and questions:
- Create an issue in the repository
- Check the troubleshooting section
- Review Docker and Streamlit documentation

---

Built with â¤ï¸ using Streamlit, LangChain, and Google AI